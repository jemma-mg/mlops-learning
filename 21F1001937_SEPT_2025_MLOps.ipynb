{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Iris Classifier using Vertex AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, you build a scikit-learn model and deploy it on infer in local environment using Google Cloud Storage for logging and tracking model and data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fe0bb78c9ce",
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This tutorial uses R.A. Fisher's Iris dataset, a small and popular dataset for machine learning experiments. Each instance has four numerical features, which are different measurements of a flower, and a target label that\n",
    "categorizes the flower into: **Iris setosa**, **Iris versicolour** and **Iris virginica**.\n",
    "\n",
    "This tutorial uses [a version of the Iris dataset available in the\n",
    "scikit-learn library](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c681f532cf64",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb",
    "tags": []
   },
   "source": [
    "## Week 1\n",
    "\n",
    "Setting up the ML pipeline for IRIS Classifier in Vertex AI platform using GCS as demonstrated in the lecture (Hands-on: Introduction to Google Cloud, Vertex AI) in your GCP account.\n",
    "\n",
    "1. Activate your GCP Trial\n",
    "2. Setup Vertex AI Workbench (Enable appropriate services/api as required)\n",
    "3. Store Training Data in Google Storage Bucket \n",
    "4. Fetch the data from Google Storage Bucket and Successfully execute the IRIS Machine Learning Training Pipeline\n",
    "5. Store the Output artifacts(Models, logs, etc) in Google cloud storage bucket with folders organized by their training execution timestamp\n",
    "6. Create a new script for inference and run the inference on eval set after fetching the models from GCS Output Artifacts Bucket\n",
    "7. Run this Training and inference for 2 times resulting in two output artifact folders in Google cloud storage bucket\n",
    "8. (Optional) Run this pipeline for two versions of data provided in github data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4464,
     "status": "ok",
     "timestamp": 1752137477124,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "### Set Google Cloud project information\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137480955,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "set_project_id",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"mlops-sept25\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137488631,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://mlops-sept25\"  # @param {type:\"string\"}\n",
    "BUCKET_NAME = \"mlops-sept25\"\n",
    "MODEL_ARTIFACT_DIR=\"iris_classifier/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2srkkUb6gOL7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mlops-sept25/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mlops-sept25' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "Copying the v1 and v2 datasets to the storage bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/v1/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  2.6 KiB/  2.6 KiB]                                                \n",
      "Operation completed over 1 objects/2.6 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/v1/data.csv {BUCKET_URI}/data/v1/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/v2/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/v2/data.csv {BUCKET_URI}/data/v2/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/raw/iris.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  3.9 KiB/  3.9 KiB]                                                \n",
      "Operation completed over 1 objects/3.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/raw/iris.csv {BUCKET_URI}/data/raw/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IRIS_DATA = f\"gs://mlops-sept25/data/raw/iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_V1 = f\"gs://mlops-sept25/data/v1/data.csv\"\n",
    "DATA_V2 = f\"gs://mlops-sept25/data/v2/data.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "Initially the data was overwritten due to same file name, used different directories after "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3330b4f12a0d"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e088ea8cd4a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e95ca1e5e07c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2d091d9e73"
   },
   "source": [
    "## Simple Decision Tree model\n",
    "Build a Decision Tree model on iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qvqSD5MDgOL8",
    "outputId": "45047f0d-064c-4bcc-9c6b-bde3ea150340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_data(dataset):\n",
    "    data = pd.read_csv(dataset)\n",
    "    print(data.head(5))\n",
    "    \n",
    "    train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "    X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_train = train.species\n",
    "    X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_test = test.species\n",
    "    \n",
    "    mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "    mod_dt.fit(X_train,y_train)\n",
    "    prediction=mod_dt.predict(X_test)\n",
    "    print('\\nThe accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))\n",
    "    \n",
    "    return mod_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(IRIS_DATA)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(DATA_V1)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "kFGdB85kgOL8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "# X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "# y_train = train.species\n",
    "# X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "# y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "9xxORpJRgOL8",
    "outputId": "72db1025-1834-4dcb-8934-416b8cb99ace",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "# mod_dt.fit(X_train,y_train)\n",
    "# prediction=mod_dt.predict(X_test)\n",
    "# print('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### Upload model artifacts and custom code to Cloud Storage\n",
    "\n",
    "Before you can deploy your model for serving, Vertex AI needs access to the following files in Cloud Storage:\n",
    "\n",
    "* `model.joblib` (model artifact)\n",
    "* `preprocessor.pkl` (model artifact)\n",
    "\n",
    "Run the following commands to upload your files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "S0pyhxkkgOL8",
    "outputId": "f88a4ba7-e223-4639-c6f8-6dd8bdc1050b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import joblib\n",
    "\n",
    "# joblib.dump(mod_dt, \"artifacts/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ca67ee52d4d9",
    "outputId": "0567f4dc-db7d-44db-9120-d62897a7db97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gsutil cp artifacts/model.joblib {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import joblib, os, datetime\n",
    "# from google.cloud import storage\n",
    "\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# output_dir = f\"{MODEL_ARTIFACT_DIR}/artifacts/{timestamp}-iris\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Save model\n",
    "# joblib.dump(mod_dt, f\"{output_dir}/iris_model.joblib\")\n",
    "\n",
    "# # Save metrics\n",
    "# with open(f\"{output_dir}/metrics.txt\", \"w\") as f:\n",
    "#     f.write(f\"accuracy: {metrics.accuracy_score(prediction, y_test):.3f}\\n\")\n",
    "\n",
    "# # Upload to GCS\n",
    "# client = storage.Client()\n",
    "# bucket = client.bucket(BUCKET_URI.split('gs://')[1])\n",
    "# for file in os.listdir(output_dir):\n",
    "#     blob = bucket.blob(f\"{output_dir}/{file}\")\n",
    "#     blob.upload_from_filename(f\"{output_dir}/{file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib, os, datetime\n",
    "from google.cloud import storage\n",
    "\n",
    "def store_to_gcs(model):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = f\"{MODEL_ARTIFACT_DIR}/artifacts/{timestamp}-iris\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(mod_dt, f\"{output_dir}/iris_model.joblib\")\n",
    "\n",
    "    # Save metrics\n",
    "    with open(f\"{output_dir}/metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"accuracy: {metrics.accuracy_score(prediction, y_test):.3f}\\n\")\n",
    "\n",
    "    # Upload to GCS\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(BUCKET_URI.split('gs://')[1])\n",
    "    for file in os.listdir(output_dir):\n",
    "        blob = bucket.blob(f\"{output_dir}/{file}\")\n",
    "        blob.upload_from_filename(f\"{output_dir}/{file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Inference script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def download_model(bucket_name, model_path, local_file=\"iris_model.joblib\"):\n",
    "    client = storage.Client()\n",
    "    blob = client.bucket(bucket_name).blob(model_path)\n",
    "    blob.download_to_filename(local_file)\n",
    "    return joblib.load(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inference(data, model_artifact):\n",
    "    # Load evaluation data - for data v1\n",
    "    eval_df = pd.read_csv(data)  # use test set\n",
    "    X_eval = eval_df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    \n",
    "    # Load model from GCS and predict\n",
    "    model = download_model(BUCKET_NAME, model_artifact)\n",
    "    preds = model.predict(X_eval)\n",
    "    eval_df['predictions'] = preds\n",
    "    print(eval_df.head())\n",
    "    \n",
    "    print('\\nAccuracy:', \"{:.3f}\".format(metrics.accuracy_score(eval_df['predictions'], eval_df['species'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load evaluation data - for data v1\n",
    "# eval_df = pd.read_csv(DATA_V1)  # use test set\n",
    "# X_eval = eval_df[['sepal_length','sepal_width','petal_length','petal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load model from GCS and predict\n",
    "# model = download_model(BUCKET_NAME, \"iris_classifier/model/artifacts/20251005-022441-iris/iris_model.joblib\")\n",
    "# preds = model.predict(X_eval)\n",
    "# eval_df['predictions'] = preds\n",
    "# print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Accuracy:', \"{:.3f}\".format(metrics.accuracy_score(eval_df['predictions'], eval_df['species'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Training and Inference 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 0.983\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(IRIS_DATA)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm iris_model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Taining and Inference 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.8          4.0           1.2          0.2  setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 0.951\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(DATA_V1)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'iris_model.joblib': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rm iris_model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Taining and Inference 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 1.000\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(DATA_V2)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "## Week 2\n",
    "\n",
    "Incorporate DVC for the local data into the homework pipeline.\n",
    "Setup DVC in IRIS Pipeline we have setup as part of Week-2 Assignment\n",
    "\n",
    "1. Setup the git repository\n",
    "2. Configure DVC to use Google Cloud storage bucket as Remote storage\n",
    "3. Augment the IRIS data to simulate the data additions and start training\n",
    "4. Demonstrate storing data and model files as part of DVC\n",
    "5. Demonstrate the ability to traverse through data versions effortlessly using dvc checkout\n",
    "* DVC Command sheet - here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Initialize Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21F1001937_SEPT_2025_MLOps.ipynb  \u001b[0m\u001b[01;34mdata\u001b[0m/             iris_model.joblib\n",
      "\u001b[01;34martifacts\u001b[0m/                        \u001b[01;34miris_classifier\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git config --global user.name \"jemma-mg\"\n",
    "# !git config --global user.email \"jemmamariyageorge@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31m21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miris_classifier/\u001b[m\n",
      "\t\u001b[31miris_model.joblib\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' >> .gitignore\n",
    ".bashrc\n",
    ".gitconfig\n",
    ".viminfo\n",
    ".cache/*\n",
    ".config/*\n",
    ".docker/*\n",
    ".gitconfig/*\n",
    ".gsutil/*\n",
    ".ipynb_checkpoints/*\n",
    ".ipython/*\n",
    ".jupyter/*\n",
    ".local/*\n",
    ".npm/*\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.gitignore\u001b[m\n",
      "\t\u001b[31m21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miris_classifier/\u001b[m\n",
      "\t\u001b[31miris_model.joblib\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' >> .gitignore\n",
    "iris_classifier/*\n",
    "iris_model.joblib\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n",
      "iris_classifier/*\n",
      "iris_model.joblib\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.gitignore\u001b[m\n",
      "\t\u001b[31m21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) 3cc7d90] Initial commit of IRIS ML pipeline\n",
      " 11 files changed, 1946 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " create mode 100644 21F1001937_SEPT_2025_MLOps.ipynb\n",
      " create mode 100644 artifacts/20251005-003900/iris_model_v1.joblib\n",
      " create mode 100644 artifacts/20251005-003900/metrics.txt\n",
      " create mode 100644 artifacts/20251005-004237-v1/metrics.txt\n",
      " create mode 100644 artifacts/20251005-005426-iris/metrics.txt\n",
      " create mode 100644 data/raw/.ipynb_checkpoints/iris-checkpoint.csv\n",
      " create mode 100644 data/raw/iris.csv\n",
      " create mode 100644 data/v1/.ipynb_checkpoints/data-checkpoint.csv\n",
      " create mode 100644 data/v1/data.csv\n",
      " create mode 100644 data/v2/data.csv\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Initial commit of IRIS ML pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' >> .gitignore\n",
    "data/*\n",
    "artifacts/*\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Configure DVC with GCS Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: dvc 3.63.0 does not provide the extra 'gcs'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~ryptography'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet dvc[gcs]\n",
    "!pip install --quiet dvc[gdrive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
