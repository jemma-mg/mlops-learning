{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Iris Classifier using Vertex AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO",
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, you build a scikit-learn model and deploy it on infer in local environment using Google Cloud Storage for logging and tracking model and data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fe0bb78c9ce",
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This tutorial uses R.A. Fisher's Iris dataset, a small and popular dataset for machine learning experiments. Each instance has four numerical features, which are different measurements of a flower, and a target label that\n",
    "categorizes the flower into: **Iris setosa**, **Iris versicolour** and **Iris virginica**.\n",
    "\n",
    "This tutorial uses [a version of the Iris dataset available in the\n",
    "scikit-learn library](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c681f532cf64",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0316df526f8"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb",
    "tags": []
   },
   "source": [
    "## Week 1\n",
    "\n",
    "Setting up the ML pipeline for IRIS Classifier in Vertex AI platform using GCS as demonstrated in the lecture (Hands-on: Introduction to Google Cloud, Vertex AI) in your GCP account.\n",
    "\n",
    "1. Activate your GCP Trial\n",
    "2. Setup Vertex AI Workbench (Enable appropriate services/api as required)\n",
    "3. Store Training Data in Google Storage Bucket \n",
    "4. Fetch the data from Google Storage Bucket and Successfully execute the IRIS Machine Learning Training Pipeline\n",
    "5. Store the Output artifacts(Models, logs, etc) in Google cloud storage bucket with folders organized by their training execution timestamp\n",
    "6. Create a new script for inference and run the inference on eval set after fetching the models from GCS Output Artifacts Bucket\n",
    "7. Run this Training and inference for 2 times resulting in two output artifact folders in Google cloud storage bucket\n",
    "8. (Optional) Run this pipeline for two versions of data provided in github data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9065e8d7f0fb"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4464,
     "status": "ok",
     "timestamp": 1752137477124,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "1fd00fa70a2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Vertex SDK for Python\n",
    "! pip3 install --upgrade --quiet  google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEglUHQk9S3"
   },
   "source": [
    "### Set Google Cloud project information\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137480955,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "set_project_id",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"mlops-sept25\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752137488631,
     "user": {
      "displayName": "da5014 1",
      "userId": "01646375301695730652"
     },
     "user_tz": -330
    },
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://mlops-sept25\"  # @param {type:\"string\"}\n",
    "BUCKET_NAME = \"mlops-sept25\"\n",
    "MODEL_ARTIFACT_DIR=\"iris_classifier/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2srkkUb6gOL7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://mlops-sept25/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'mlops-sept25' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "Copying the v1 and v2 datasets to the storage bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/v1/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  2.6 KiB/  2.6 KiB]                                                \n",
      "Operation completed over 1 objects/2.6 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/v1/data.csv {BUCKET_URI}/data/v1/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/v2/data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/v2/data.csv {BUCKET_URI}/data/v2/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/raw/iris.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  3.9 KiB/  3.9 KiB]                                                \n",
      "Operation completed over 1 objects/3.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/raw/iris.csv {BUCKET_URI}/data/raw/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IRIS_DATA = f\"gs://mlops-sept25/data/raw/iris.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_V1 = f\"gs://mlops-sept25/data/v1/data.csv\"\n",
    "DATA_V2 = f\"gs://mlops-sept25/data/v2/data.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "Initially the data was overwritten due to same file name, used different directories after "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3330b4f12a0d"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e088ea8cd4a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3938f6d37a1"
   },
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e95ca1e5e07c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c2d091d9e73"
   },
   "source": [
    "## Simple Decision Tree model\n",
    "Build a Decision Tree model on iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qvqSD5MDgOL8",
    "outputId": "45047f0d-064c-4bcc-9c6b-bde3ea150340",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_data(dataset):\n",
    "    data = pd.read_csv(dataset)\n",
    "    print(data.head(5))\n",
    "    \n",
    "    train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "    X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_train = train.species\n",
    "    X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_test = test.species\n",
    "    \n",
    "    mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "    mod_dt.fit(X_train,y_train)\n",
    "    prediction=mod_dt.predict(X_test)\n",
    "    print('\\nThe accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))\n",
    "    \n",
    "    return mod_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(IRIS_DATA)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(DATA_V1)\n",
    "# data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "kFGdB85kgOL8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, test = train_test_split(data, test_size = 0.4, stratify = data['species'], random_state = 42)\n",
    "# X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "# y_train = train.species\n",
    "# X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "# y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "9xxORpJRgOL8",
    "outputId": "72db1025-1834-4dcb-8934-416b8cb99ace",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "# mod_dt.fit(X_train,y_train)\n",
    "# prediction=mod_dt.predict(X_test)\n",
    "# print('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd"
   },
   "source": [
    "### Upload model artifacts and custom code to Cloud Storage\n",
    "\n",
    "Before you can deploy your model for serving, Vertex AI needs access to the following files in Cloud Storage:\n",
    "\n",
    "* `model.joblib` (model artifact)\n",
    "* `preprocessor.pkl` (model artifact)\n",
    "\n",
    "Run the following commands to upload your files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "S0pyhxkkgOL8",
    "outputId": "f88a4ba7-e223-4639-c6f8-6dd8bdc1050b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import joblib\n",
    "\n",
    "# joblib.dump(mod_dt, \"artifacts/model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ca67ee52d4d9",
    "outputId": "0567f4dc-db7d-44db-9120-d62897a7db97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gsutil cp artifacts/model.joblib {BUCKET_URI}/{MODEL_ARTIFACT_DIR}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import joblib, os, datetime\n",
    "# from google.cloud import storage\n",
    "\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# output_dir = f\"{MODEL_ARTIFACT_DIR}/artifacts/{timestamp}-iris\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Save model\n",
    "# joblib.dump(mod_dt, f\"{output_dir}/iris_model.joblib\")\n",
    "\n",
    "# # Save metrics\n",
    "# with open(f\"{output_dir}/metrics.txt\", \"w\") as f:\n",
    "#     f.write(f\"accuracy: {metrics.accuracy_score(prediction, y_test):.3f}\\n\")\n",
    "\n",
    "# # Upload to GCS\n",
    "# client = storage.Client()\n",
    "# bucket = client.bucket(BUCKET_URI.split('gs://')[1])\n",
    "# for file in os.listdir(output_dir):\n",
    "#     blob = bucket.blob(f\"{output_dir}/{file}\")\n",
    "#     blob.upload_from_filename(f\"{output_dir}/{file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib, os, datetime\n",
    "from google.cloud import storage\n",
    "\n",
    "def store_to_gcs(model):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = f\"{MODEL_ARTIFACT_DIR}/artifacts/{timestamp}-iris\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(mod_dt, f\"{output_dir}/iris_model.joblib\")\n",
    "\n",
    "    # Save metrics\n",
    "    with open(f\"{output_dir}/metrics.txt\", \"w\") as f:\n",
    "        f.write(f\"accuracy: {metrics.accuracy_score(prediction, y_test):.3f}\\n\")\n",
    "\n",
    "    # Upload to GCS\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(BUCKET_URI.split('gs://')[1])\n",
    "    for file in os.listdir(output_dir):\n",
    "        blob = bucket.blob(f\"{output_dir}/{file}\")\n",
    "        blob.upload_from_filename(f\"{output_dir}/{file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Inference script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def download_model(bucket_name, model_path, local_file=\"iris_model.joblib\"):\n",
    "    client = storage.Client()\n",
    "    blob = client.bucket(bucket_name).blob(model_path)\n",
    "    blob.download_to_filename(local_file)\n",
    "    return joblib.load(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_inference(data, model_artifact):\n",
    "    # Load evaluation data - for data v1\n",
    "    eval_df = pd.read_csv(data)  # use test set\n",
    "    X_eval = eval_df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    \n",
    "    # Load model from GCS and predict\n",
    "    model = download_model(BUCKET_NAME, model_artifact)\n",
    "    preds = model.predict(X_eval)\n",
    "    eval_df['predictions'] = preds\n",
    "    print(eval_df.head())\n",
    "    \n",
    "    print('\\nAccuracy:', \"{:.3f}\".format(metrics.accuracy_score(eval_df['predictions'], eval_df['species'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load evaluation data - for data v1\n",
    "# eval_df = pd.read_csv(DATA_V1)  # use test set\n",
    "# X_eval = eval_df[['sepal_length','sepal_width','petal_length','petal_width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load model from GCS and predict\n",
    "# model = download_model(BUCKET_NAME, \"iris_classifier/model/artifacts/20251005-022441-iris/iris_model.joblib\")\n",
    "# preds = model.predict(X_eval)\n",
    "# eval_df['predictions'] = preds\n",
    "# print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Accuracy:', \"{:.3f}\".format(metrics.accuracy_score(eval_df['predictions'], eval_df['species'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Training and Inference 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 0.983\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(IRIS_DATA)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-024852-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm iris_model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Taining and Inference 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.8          4.0           1.2          0.2  setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 0.951\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(DATA_V1)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-025002-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'iris_model.joblib': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rm iris_model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "### Taining and Inference 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "\n",
      "The accuracy of the Decision Tree is 1.000\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_data(DATA_V2)\n",
    "store_to_gcs(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V1, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 0.980\n"
     ]
    }
   ],
   "source": [
    "get_inference(IRIS_DATA, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.1          3.5           1.4          0.2  setosa      setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa      setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa      setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa      setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa      setosa\n",
      "\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "get_inference(DATA_V2, \"iris_classifier/model/artifacts/20251005-025150-iris/iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "## Week 2\n",
    "\n",
    "Incorporate DVC for the local data into the homework pipeline.\n",
    "Setup DVC in IRIS Pipeline we have setup as part of Week-2 Assignment\n",
    "\n",
    "1. Setup the git repository\n",
    "2. Configure DVC to use Google Cloud storage bucket as Remote storage\n",
    "3. Augment the IRIS data to simulate the data additions and start training\n",
    "4. Demonstrate storing data and model files as part of DVC\n",
    "5. Demonstrate the ability to traverse through data versions effortlessly using dvc checkout\n",
    "* DVC Command sheet - here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Initialize Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21F1001937_SEPT_2025_MLOps.ipynb  \u001b[0m\u001b[01;34mdata\u001b[0m/             iris_model.joblib\n",
      "\u001b[01;34martifacts\u001b[0m/                        \u001b[01;34miris_classifier\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git config --global user.name \"jemma-mg\"\n",
    "# !git config --global user.email \"jemmamariyageorge@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.bashrc\u001b[m\n",
      "\t\u001b[31m.cache/\u001b[m\n",
      "\t\u001b[31m.config/\u001b[m\n",
      "\t\u001b[31m.docker/\u001b[m\n",
      "\t\u001b[31m.gitconfig\u001b[m\n",
      "\t\u001b[31m.gsutil/\u001b[m\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31m.ipython/\u001b[m\n",
      "\t\u001b[31m.jupyter/\u001b[m\n",
      "\t\u001b[31m.local/\u001b[m\n",
      "\t\u001b[31m.npm/\u001b[m\n",
      "\t\u001b[31m21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31miris_classifier/\u001b[m\n",
      "\t\u001b[31miris_model.joblib\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' > .gitignore\n",
    ".bashrc\n",
    ".gitconfig\n",
    ".viminfo\n",
    ".cache/*\n",
    ".config/*\n",
    ".docker/*\n",
    ".gitconfig/*\n",
    ".gsutil/*\n",
    ".ipynb_checkpoints/*\n",
    ".ipython/*\n",
    "*/.ipynb_checkpoints/*\n",
    "*/.ipython/*\n",
    ".jupyter/*\n",
    ".local/*\n",
    ".npm/*\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      "*/.ipynb_checkpoints/*\n",
      "*/.ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .dvc/config\u001b[m\n",
      "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31martifacts/20251005-004237-v1/iris_model.joblib\u001b[m\n",
      "\t\u001b[31martifacts/20251005-005426-iris/iris_model.joblib\u001b[m\n",
      "\t\u001b[31mdata/v1/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/v1/.ipynb_checkpoints/data.csv-checkpoint.dvc\u001b[m\n",
      "\t\u001b[31mdata/v2/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/v2/.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31miris_classifier/\u001b[m\n",
      "\t\u001b[31miris_model.joblib\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' >> .gitignore\n",
    "iris_classifier/*\n",
    "iris_model.joblib\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n",
      "iris_classifier/*\n",
      "iris_model.joblib\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.gitignore\u001b[m\n",
      "\t\u001b[31m21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[31martifacts/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << 'EOF' >> .gitignore\n",
    "artifacts/*\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      "*/.ipynb_checkpoints/*\n",
      "*/.ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n",
      "artifacts/*\n",
      "artifacts/*\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 05913fd] Initial commit of IRIS ML pipeline\n",
      " 2 files changed, 104 insertions(+), 12 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"Initial commit of IRIS ML pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Configure DVC with GCS Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: dvc 3.63.0 does not provide the extra 'gcs'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~ryptography'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet dvc[gcs]\n",
    "!pip install --quiet dvc[gdrive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 57eb339] Initialize DVC\n",
      " 3 files changed, 6 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Initialize DVC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'gcsremote' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !dvc remote add -f -d gcsremote gs://mlops-sept25/dvc-store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !dvc remote add -d gcsremote gs://mlops-sept25/dvc-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mgcsremote       \u001b[0m\u001b[32mgs://mlops-sept25/dvc-store     \u001b[0m\u001b[32m(default)\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[core]\n",
      "    remote = gcsremote\n",
      "['remote \"gcsremote\"']\n",
      "    url = gs://mlops-sept25/dvc-store\n"
     ]
    }
   ],
   "source": [
    "!cat .dvc/config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !dvc remote modify gcsremote project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Credentialed Accounts\n",
      "ACTIVE  ACCOUNT\n",
      "*       451836298879-compute@developer.gserviceaccount.com\n",
      "\n",
      "To set the active account, run:\n",
      "    $ gcloud config set account `ACCOUNT`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Track Iris Dataset with DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cat << 'EOF' >> .gitignore\n",
    "# data/*\n",
    "# !data/**/*.dvc\n",
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !echo -e \"data/**\\n!data/**/*.dvc\" >> .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n",
      "iris_classifier/*\n",
      "iris_model.joblib\n",
      "data/*\n",
      "artifacts/*\n",
      "!data/**/*.dvc\n"
     ]
    }
   ],
   "source": [
    "cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v1/data.csv |0.00 [00:00,     ?fil\u001b[A\n",
      "Adding...                                                                       \u001b[A\n",
      "\u001b[31mERROR\u001b[39m:  output 'data/v1/data.csv' is already tracked by SCM (e.g. Git).\n",
      "    You can remove it from Git, then add to DVC.\n",
      "        To stop tracking from Git:\n",
      "            git rm -r --cached 'data/v1/data.csv'\n",
      "            git commit -m \"stop tracking data/v1/data.csv\" \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add data/v1/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm 'data/v1/data.csv'\n"
     ]
    }
   ],
   "source": [
    "!git rm -r --cached 'data/v1/data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master aa36b67] stop tracking data/v1/data.csv\n",
      " 1 file changed, 102 deletions(-)\n",
      " delete mode 100644 data/v1/data.csv\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"stop tracking data/v1/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v1/data.csv |0.00 [00:00,     ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/v1/data.csv to cache      0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v1/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  8.46file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v1/data.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add data/v1/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following paths are ignored by one of your .gitignore files:\n",
      "data/v1\n",
      "\u001b[33mhint: Use -f if you really want to add them.\u001b[m\n",
      "\u001b[33mhint: Turn this message off by running\u001b[m\n",
      "\u001b[33mhint: \"git config advice.addIgnoredFile false\"\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!git add data/v1/data.csv.dvc .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master d69a849] Track data/v1/data.csv with DVC\n",
      " 1 file changed, 1 insertion(+)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Track data/v1/data.csv with DVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master d69a849] Track data/v1/data.csv with DVC\n",
      " 1 file changed, 1 insertion(+)\n"
     ]
    }
   ],
   "source": [
    "# !git tag -a \"v1.0.0\" -m \"Track data/v1/data.csv with DVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: dvc 3.63.0 does not provide the extra 'gcs'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet \"dvc[gcs]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR\u001b[39m: unexpected error - gs is supported, but requires 'dvc-gs' to be installed: No module named 'dvc_gs'\n",
      "\n",
      "\u001b[33mHaving any troubles?\u001b[0m Hit us up at \u001b[34mhttps://dvc.org/support\u001b[0m, we are always happy to help!\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dvc-gs\n",
      "  Downloading dvc_gs-3.0.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: dvc in /opt/conda/lib/python3.10/site-packages (from dvc-gs) (3.63.0)\n",
      "Requirement already satisfied: gcsfs>=2022.11.0 in /opt/conda/lib/python3.10/site-packages (from dvc-gs) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (3.12.15)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (5.2.1)\n",
      "Requirement already satisfied: fsspec==2025.9.0 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2025.9.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2.19.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gcsfs>=2022.11.0->dvc-gs) (2.32.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2022.11.0->dvc-gs) (3.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs>=2022.11.0->dvc-gs) (0.6.1)\n",
      "Requirement already satisfied: celery in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (5.5.3)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.4.6)\n",
      "Requirement already satisfied: configobj>=5.0.9 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (5.0.9)\n",
      "Requirement already satisfied: distro>=1.3 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.9.0)\n",
      "Requirement already satisfied: dpath<3,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (2.2.0)\n",
      "Requirement already satisfied: dulwich in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.24.2)\n",
      "Requirement already satisfied: dvc-data<3.17,>=3.16.2 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (3.16.12)\n",
      "Requirement already satisfied: dvc-http>=2.29.0 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (2.32.0)\n",
      "Requirement already satisfied: dvc-objects in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (5.1.2)\n",
      "Requirement already satisfied: dvc-render<2,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.0.2)\n",
      "Requirement already satisfied: dvc-studio-client<1,>=0.21 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.22.0)\n",
      "Requirement already satisfied: dvc-task<1,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.40.2)\n",
      "Requirement already satisfied: flatten_dict<1,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.4.2)\n",
      "Requirement already satisfied: flufl.lock<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (8.2.0)\n",
      "Requirement already satisfied: funcy>=1.14 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (2.0)\n",
      "Requirement already satisfied: grandalf<1,>=0.7 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.8)\n",
      "Requirement already satisfied: gto<2,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.8.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.3.2)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.0.10)\n",
      "Requirement already satisfied: kombu in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (5.5.4)\n",
      "Requirement already satisfied: networkx>=2.5 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (3.4.2)\n",
      "Requirement already satisfied: omegaconf in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (2.3.0)\n",
      "Requirement already satisfied: packaging>=19 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.10.3 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.12.1)\n",
      "Requirement already satisfied: platformdirs<5,>=3.1.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (4.3.8)\n",
      "Requirement already satisfied: psutil>=5.8 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (5.9.3)\n",
      "Requirement already satisfied: pydot>=1.2.4 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (4.0.1)\n",
      "Requirement already satisfied: pygtrie>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (2.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (3.2.4)\n",
      "Requirement already satisfied: rich>=12 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (13.9.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.11 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.18.15)\n",
      "Requirement already satisfied: scmrepo<4,>=3.5.2 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (3.5.2)\n",
      "Requirement already satisfied: shortuuid>=0.5 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.0.13)\n",
      "Requirement already satisfied: shtab<2,>=1.3.4 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (1.7.2)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.9.0)\n",
      "Requirement already satisfied: tomlkit>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.13.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.63.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (4.67.1)\n",
      "Requirement already satisfied: voluptuous>=0.11.7 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (0.15.2)\n",
      "Requirement already satisfied: zc.lockfile>=1.2.1 in /opt/conda/lib/python3.10/site-packages (from dvc->dvc-gs) (4.0)\n",
      "Requirement already satisfied: dictdiffer>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc->dvc-gs) (0.9.0)\n",
      "Requirement already satisfied: diskcache>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc->dvc-gs) (5.6.3)\n",
      "Requirement already satisfied: sqltrie<1,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc->dvc-gs) (0.11.2)\n",
      "Requirement already satisfied: orjson<4,>=3 in /opt/conda/lib/python3.10/site-packages (from dvc-data<3.17,>=3.16.2->dvc->dvc-gs) (3.11.3)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.1 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (4.2.1)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (5.1.0)\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (8.1.8)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (0.3.1)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (1.1.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from celery->dvc->dvc-gs) (2.9.0.post0)\n",
      "Requirement already satisfied: six<2.0,>=1.12 in /opt/conda/lib/python3.10/site-packages (from flatten_dict<1,>=0.4.1->dvc->dvc-gs) (1.17.0)\n",
      "Requirement already satisfied: atpublic in /opt/conda/lib/python3.10/site-packages (from flufl.lock<9,>=8.1.0->dvc->dvc-gs) (5.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc->dvc-gs) (0.4)\n",
      "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc->dvc-gs) (2.11.9)\n",
      "Requirement already satisfied: semver>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc->dvc-gs) (3.0.4)\n",
      "Requirement already satisfied: typer>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from gto<2,>=1.6.0->dvc->dvc-gs) (0.19.2)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in /opt/conda/lib/python3.10/site-packages (from kombu->dvc->dvc-gs) (5.3.1)\n",
      "Requirement already satisfied: tzdata>=2025.2 in /opt/conda/lib/python3.10/site-packages (from kombu->dvc->dvc-gs) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc->dvc-gs) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc->dvc-gs) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.6.0->dvc->dvc-gs) (0.4.1)\n",
      "Requirement already satisfied: gitpython>3 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc->dvc-gs) (3.1.45)\n",
      "Requirement already satisfied: pygit2>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc->dvc-gs) (1.18.2)\n",
      "Requirement already satisfied: asyncssh<3,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc->dvc-gs) (2.21.1)\n",
      "Requirement already satisfied: aiohttp-retry>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from scmrepo<4,>=3.5.2->dvc->dvc-gs) (2.9.1)\n",
      "Requirement already satisfied: cryptography>=39.0 in /opt/conda/lib/python3.10/site-packages (from asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc->dvc-gs) (43.0.3)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in /opt/conda/lib/python3.10/site-packages (from click-repl>=0.2.0->celery->dvc->dvc-gs) (3.0.52)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=39.0->asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc->dvc-gs) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=39.0->asyncssh<3,>=2.13.1->scmrepo<4,>=3.5.2->dvc->dvc-gs) (2.22)\n",
      "Requirement already satisfied: urllib3>=2.2.2 in /opt/conda/lib/python3.10/site-packages (from dulwich->dvc->dvc-gs) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>3->scmrepo<4,>=3.5.2->dvc->dvc-gs) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<4,>=3.5.2->dvc->dvc-gs) (5.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.1->dvc->dvc-gs) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf->dvc->dvc-gs) (6.0.2)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from iterative-telemetry>=0.0.7->dvc->dvc-gs) (1.4.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from iterative-telemetry>=0.0.7->dvc->dvc-gs) (3.19.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery->dvc->dvc-gs) (0.2.13)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->gcsfs>=2022.11.0->dvc-gs) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->gcsfs>=2022.11.0->dvc-gs) (2025.8.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12->dvc->dvc-gs) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=12->dvc->dvc-gs) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12->dvc->dvc-gs) (0.1.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.11->dvc->dvc-gs) (0.2.12)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.4.1->gto<2,>=1.6.0->dvc->dvc-gs) (1.5.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from zc.lockfile>=1.2.1->dvc->dvc-gs) (80.9.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs>=2022.11.0->dvc-gs) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2022.11.0->dvc-gs) (3.3.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (6.31.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2022.11.0->dvc-gs) (1.26.1)\n",
      "Downloading dvc_gs-3.0.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: dvc-gs\n",
      "Successfully installed dvc-gs-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dvc-gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: dvc-gs\n",
      "Version: 3.0.2\n",
      "Summary: gs plugin for dvc\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Iterative <support@dvc.org>\n",
      "License: Apache License 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: dvc, gcsfs\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show dvc-gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Pushing\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Augment the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_v1 = pd.read_csv('data/v1/data.csv')\n",
    "data_v2 = pd.read_csv('data/v2/data.csv')\n",
    "\n",
    "# # Simulate new rows (data augmentation)\n",
    "# new_data = data.sample(20, replace=True)  # duplicate some rows for example\n",
    "augmented_data = pd.concat([data_v1, data_v2], ignore_index=True)\n",
    "\n",
    "augmented_data.to_csv('data/v2/data_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v2/data_augmented.csv |0.00 [00:00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v2/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 28.47file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v2/data_augmented.csv.dvc data/v2/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m[master 4b4b681] Add augmented Iris dataset v2\n",
      " 1 file changed, 5 insertions(+)\n",
      " create mode 100644 data/v2/data_augmented.csv.dvc\n",
      "Collecting                                            |2.00 [00:00,  130entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      " 50% Querying cache in 'mlops-sept25/dvc-store/files/md5'|▌|1/2 [00:00<00:00,  7\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Track augmented dataset with DVC:\n",
    "\n",
    "!dvc add data/v2/data_augmented.csv\n",
    "!git add data/v2/data_augmented.csv.dvc\n",
    "!git commit -m \"Add augmented Iris dataset v2\"\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !dvc list .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and pipelines are up to date.                                              \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |0.00 [00:00,    ?entry/s]\n",
      "Comparing indexes                                    |1.00 [00:00, 1.95kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[31mD\u001b[0m       data/v1/data.csv\n",
      "\u001b[31mD\u001b[0m       data/v2/data_augmented.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlops-sept25/dvc-store/files/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://mlops-sept25/dvc-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mgcsremote       \u001b[0m\u001b[32mgs://mlops-sept25/dvc-store     \u001b[0m\u001b[32m(default)\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc remote list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet dvc-gs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v1/data.csv |0.00 [00:00,     ?fil\u001b[A\n",
      "Adding...                                                                       \u001b[A\n",
      "\u001b[31mERROR\u001b[39m: output 'data/v1/data.csv' does not exist: [Errno 2] No such file or directory: '/home/jupyter/data/v1/data.csv'\n",
      "\u001b[0mThe following paths are ignored by one of your .gitignore files:\n",
      "data/v1\n",
      "\u001b[33mhint: Use -f if you really want to add them.\u001b[m\n",
      "\u001b[33mhint: Turn this message off by running\u001b[m\n",
      "\u001b[33mhint: \"git config advice.addIgnoredFile false\"\u001b[m\n",
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .dvc/config\u001b[m\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/v1/data.csv\n",
    "!git add data/v1/data.csv.dvc .gitignore\n",
    "!git commit -m \"Track Iris v1 dataset with DVC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v1/data.csv |0.00 [00:00,     ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v1/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 17.85file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v1/data.csv.dvc data/v1/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m[master 9195d98] Track Iris v1 dataset with DVC\n",
      " 2 files changed, 5 insertions(+), 2 deletions(-)\n",
      " create mode 100644 data/v1/data.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/v1/data.csv\n",
    "!git add data/v1/data.csv.dvc .gitignore\n",
    "!git commit -m \"Track Iris v1 dataset with DVC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |2.00 [00:00,  132entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/2 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/3.77k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      " 50%|█████     |Pushing to gs                     1/2 [00:00<00:00,  6.93file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/2.64k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "2 files pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Now we have two versions of data tracked in DVC\n",
    "\n",
    "* version1 - data/v1/data.csv.dvc\n",
    "* version2 - data/v2/data_augmented.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlops-sept25/dvc-store/files/md5/92/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/92/03b75e931cbba1e74a1028025169bf\n",
      "\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/e5854ee4196b617ce57e311bf88962\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://mlops-sept25/dvc-store/files/md5/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                              |5.00 [00:00,  873entry/s]\n",
      "Comparing indexes                                    |6.00 [00:00, 1.05kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc pull      # fetch files from GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |5.00 [00:00, 17.5entry/s]\n",
      "Comparing indexes                                     |6.00 [00:00,  705entry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout # apply correct versions to workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Integrate DVC into Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "##### The joblib file contains the trained model artifacts including model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model = joblib.load(\"iris_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 9\n",
      "Feature indices: [ 3 -2  2  3 -2 -2  3 -2 -2]\n",
      "Thresholds: [ 0.7        -2.          4.95000005  1.64999998 -2.         -2.\n",
      "  1.69999999 -2.         -2.        ]\n",
      "Leaf values: [[[0.33333333 0.33333333 0.33333333]]\n",
      "\n",
      " [[1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.5        0.5       ]]\n",
      "\n",
      " [[0.         0.93548387 0.06451613]]\n",
      "\n",
      " [[0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.33333333 0.66666667]]\n",
      "\n",
      " [[0.         0.03448276 0.96551724]]\n",
      "\n",
      " [[0.         0.33333333 0.66666667]]\n",
      "\n",
      " [[0.         0.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "# Access the trained tree\n",
    "tree = model.tree_\n",
    "\n",
    "# Number of nodes\n",
    "print(\"Number of nodes:\", tree.node_count)\n",
    "\n",
    "# Feature indices used at each split\n",
    "print(\"Feature indices:\", tree.feature)\n",
    "\n",
    "# Thresholds at each split\n",
    "print(\"Thresholds:\", tree.threshold)\n",
    "\n",
    "# Values at each leaf (class counts)\n",
    "print(\"Leaf values:\", tree.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: feature=3, threshold=0.7000000029802322, value=[[0.33333333 0.33333333 0.33333333]]\n",
      "Node 1: feature=-2, threshold=-2.0, value=[[1. 0. 0.]]\n",
      "Node 2: feature=2, threshold=4.950000047683716, value=[[0.  0.5 0.5]]\n",
      "Node 3: feature=3, threshold=1.649999976158142, value=[[0.         0.93548387 0.06451613]]\n",
      "Node 4: feature=-2, threshold=-2.0, value=[[0. 1. 0.]]\n",
      "Node 5: feature=-2, threshold=-2.0, value=[[0.         0.33333333 0.66666667]]\n",
      "Node 6: feature=3, threshold=1.699999988079071, value=[[0.         0.03448276 0.96551724]]\n",
      "Node 7: feature=-2, threshold=-2.0, value=[[0.         0.33333333 0.66666667]]\n",
      "Node 8: feature=-2, threshold=-2.0, value=[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(tree.node_count):\n",
    "    print(f\"Node {i}: feature={tree.feature[i]}, threshold={tree.threshold[i]}, value={tree.value[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "##### Previously I had missed to tag the commits -> re running the parts again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m4b4b681\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mmaster\u001b[m\u001b[33m)\u001b[m Add augmented Iris dataset v2\n",
      "\u001b[33m9195d98\u001b[m Track Iris v1 dataset with DVC\n",
      "\u001b[33md69a849\u001b[m Track data/v1/data.csv with DVC\n",
      "\u001b[33maa36b67\u001b[m stop tracking data/v1/data.csv\n",
      "\u001b[33m57eb339\u001b[m Initialize DVC\n",
      "\u001b[33m05913fd\u001b[m Initial commit of IRIS ML pipeline\n",
      "\u001b[33m3cc7d90\u001b[m Initial commit of IRIS ML pipeline\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[core]\n",
      "    remote = gcsremote\n",
      "['remote \"gcsremote\"']\n",
      "    url = gs://mlops-sept25/dvc-store\n"
     ]
    }
   ],
   "source": [
    "!cat .dvc/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v1/data.csv |0.00 [00:00,     ?fil\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v1/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 30.36file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v1/data.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m[master c3be2db] Track Iris v1 dataset with DVC\n",
      " 5 files changed, 1424 insertions(+), 42 deletions(-)\n",
      " create mode 100644 data/v1/.gitignore\n",
      " create mode 100644 data/v1/.ipynb_checkpoints/data.csv-checkpoint.dvc\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/v1/data.csv\n",
    "!git add data/v1/data.csv.dvc .gitignore data/v1/.gitignore data/v1/.ipynb_checkpoints/data.csv-checkpoint.dvc .dvc/config 21F1001937_SEPT_2025_MLOps.ipynb \n",
    "!git commit -m \"Track Iris v1 dataset with DVC\"\n",
    "!git tag -a \"v1.1.0\" -m \"Data version 1 - Track data/v1/data.csv with DVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |3.00 [00:00,  177entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      " 50% Querying cache in 'mlops-sept25/dvc-store/files/md5'|▌|1/2 [00:00<00:00,  8\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data.csv\n"
     ]
    }
   ],
   "source": [
    "!cat data/v1/.gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_augmented.csv\n"
     ]
    }
   ],
   "source": [
    "!cat data/v2/.gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v2/data_augmented.csv |0.00 [00:00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v2/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 25.65file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v2/data_augmented.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0mfatal: pathspec 'data/v2/.ipynb_checkpoints/data.csv-checkpoint.dvc' did not match any files\n",
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mdata/v2/.gitignore\u001b[m\n",
      "\t\u001b[31mdata/v2/.ipynb_checkpoints/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "fatal: tag 'v1.2.0' already exists\n"
     ]
    }
   ],
   "source": [
    "### Track augmented dataset with DVC:\n",
    "\n",
    "!dvc add data/v2/data_augmented.csv \n",
    "!git add data/v2/data_augmented.csv.dvc .gitignore data/v2/.gitignore data/v2/.ipynb_checkpoints/* data/v2/.ipynb_checkpoints/data.csv-checkpoint.dvc .dvc/config 21F1001937_SEPT_2025_MLOps.ipynb \n",
    "!git commit -m \"Add augmented Iris dataset v2\"\n",
    "!git tag -a \"v1.2.0\" -m \"Data version 2 - Track data/v2/data_augmented.csv with DVC\"\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/v2/data_augmented.csv |0.00 [00:00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/jupyter/data/v2/dat0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 18.44file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/v2/data_augmented.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "### Track augmented dataset with DVC:\n",
    "\n",
    "!dvc add data/v2/data_augmented.csv \n",
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\t\u001b[32mmodified:   .gitignore\u001b[m\n",
      "\t\u001b[32mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\t\u001b[32mnew file:   data/v2/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   data/v2/.ipynb_checkpoints/data-checkpoint.csv\u001b[m\n",
      "\t\u001b[32mnew file:   data/v2/.ipynb_checkpoints/data_augmented-checkpoint.csv\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "nothing to commit, working tree clean\n",
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      " 50% Querying cache in 'mlops-sept25/dvc-store/files/md5'|▌|1/2 [00:00<00:00,  8\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Add augmented Iris dataset v2\"\n",
    "!git tag -a \"v1.2.1\" -m \"Data version 2 - Track data/v2/data_augmented.csv with DVC\"\n",
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlops-sept25/dvc-store/files/md5/92/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/92/03b75e931cbba1e74a1028025169bf\n",
      "\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/e5854ee4196b617ce57e311bf88962\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://mlops-sept25/dvc-store/files/md5/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://mlops-sept25/dvc-store/files/md5/92/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/92/03b75e931cbba1e74a1028025169bf\n",
      "\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/:\n",
      "gs://mlops-sept25/dvc-store/files/md5/97/e5854ee4196b617ce57e311bf88962\n"
     ]
    }
   ],
   "source": [
    "### Pu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Pulling the version 2 data from dvc with remote GCS bucket - running the training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\t21F1001937_SEPT_2025_MLOps.ipynb\n",
      "HEAD is now at 4816e0d Add augmented Iris dataset v2\n",
      "Collecting                                            |3.00 [00:00,  141entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                              |7.00 [00:00,  808entry/s]\n",
      "Comparing indexes                                    |8.00 [00:00, 1.38kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "Building workspace index                              |7.00 [00:00, 27.5entry/s]\n",
      "Comparing indexes                                    |8.00 [00:00, 1.17kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout \"v1.2.1\"\n",
    "!dvc pull\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import joblib, os, datetime\n",
    "\n",
    "MODEL_DIR = \"artifacts\"\n",
    "\n",
    "def train_data(dataset):\n",
    "    # Load dataset\n",
    "    data = pd.read_csv(dataset)\n",
    "    \n",
    "    # Train/test split\n",
    "    train, test = train_test_split(data, test_size=0.4, stratify=data['species'], random_state=42)\n",
    "    X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_train = train['species']\n",
    "    X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    y_test = test['species']\n",
    "    \n",
    "    # Train model\n",
    "    model = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    prediction = model.predict(X_test)\n",
    "    acc = metrics.accuracy_score(prediction, y_test)\n",
    "    print(f\"\\nAccuracy: {acc:.3f}\")\n",
    "    \n",
    "    # Save model and metrics\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = os.path.join(MODEL_DIR, f\"{timestamp}-iris\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    model_file = os.path.join(output_dir, \"iris_model.joblib\")\n",
    "    metrics_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "    \n",
    "    joblib.dump(model, model_file)\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        f.write(f\"accuracy: {acc:.3f}\\n\")\n",
    "    \n",
    "    return output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'artifacts/20251005-153723-iris'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data(\"data/v2/data_augmented.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !sed -i '/artifacts\\/20251005-153723-iris.dvc/d' .gitignore\n",
    "!sed -i '/artifacts\\/*/d' .gitignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".bashrc\n",
      ".gitconfig\n",
      ".viminfo\n",
      ".cache/*\n",
      ".config/*\n",
      ".docker/*\n",
      ".gitconfig/*\n",
      ".gsutil/*\n",
      ".ipynb_checkpoints/*\n",
      ".ipython/*\n",
      "*/.ipynb_checkpoints/*\n",
      "*/.ipython/*\n",
      ".jupyter/*\n",
      ".local/*\n",
      ".npm/*\n",
      "iris_classifier/*\n",
      "iris_model.joblib\n"
     ]
    }
   ],
   "source": [
    "!cat .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in artifacts/20251005-153723-iris |0.00 [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding artifacts/20251005-153723-iris 0/2 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "Checking out /home/jupyter/artifacts/20251005-153723-iris |0.00 [00:00,    ?file\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 28.74file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add artifacts/.gitignore artifacts/20251005-153723-iris.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m[detached HEAD 1b8d28b] Add model trained on v2 dataset with metrics\n",
      " 2 files changed, 6 insertions(+), 2 deletions(-)\n",
      " create mode 100644 artifacts/20251005-153723-iris.dvc\n",
      "Collecting                                            |6.00 [00:00,  146entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      "  0% Querying cache in 'mlops-sept25/dvc-store/files/md5'| |1/4096 [00:00<10:35,\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Pushing to gs                         0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "  0%|          |Pushing to gs                         0/2 [00:00<?,     ?file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/m0.00/16.0 [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/0.00/2.33k [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "100%|██████████|Pushing to gs                     2/2 [00:00<00:00, 12.11file/s]\u001b[A\n",
      "\n",
      "!\u001b[A\u001b[A\n",
      "\n",
      "  0%|          |/home/jupyter/.dvc/cache/files/md0.00/148 [00:00<?,        ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████|/home/jupyter/.dvc/cache/files148/148 [00:00<00:00,    1.34kB/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "  0%|          |Pushing to gs                     3/? [00:00<00:00, 10.52file/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "3 files pushed\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "TIMESTAMPED_ARTIFACT=\"artifacts/20251005-153723-iris\"\n",
    "\n",
    "# Replace <timestamped-folder> with the folder returned by train_data()\n",
    "!dvc add {TIMESTAMPED_ARTIFACT}\n",
    "\n",
    "# Track DVC metadata in Git\n",
    "!git add {TIMESTAMPED_ARTIFACT}.dvc .gitignore\n",
    "!git commit -m \"Add model trained on v2 dataset with metrics\"\n",
    "\n",
    "# Push to DVC remote (GCS)\n",
    "!dvc push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHEAD detached at \u001b[mv1.2.1\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .gitignore\u001b[m\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31martifacts/20251005-153723-iris/\u001b[m\n",
      "\t\u001b[31mdata/v1/.ipynb_checkpoints/data.csv\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in artifacts/20251005-153723-iris |0.00 [0\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "Checking out /home/jupyter/artifacts/20251005-153723-iris |0.00 [00:00,    ?file\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 31.69file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add artifacts/.gitignore artifacts/20251005-153723-iris.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m[detached HEAD f03e76e] Add model trained on v2 dataset with metrics\n",
      " 2 files changed, 103 insertions(+)\n",
      " create mode 100644 artifacts/.gitignore\n",
      " create mode 100644 data/v1/.ipynb_checkpoints/data.csv\n",
      "fatal: tag 'v1.2.2' already exists\n",
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Querying remote cache|                          |0/0 [00:00<?,    ?files/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in 'mlops-sept25/dvc-store/files/md5'| |0/? [00:00<?,    ?fi\u001b[A\n",
      " 50% Querying cache in 'mlops-sept25/dvc-store/files/md5'|▌|1/2 [00:00<00:00,  7\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "Everything is up to date.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "TIMESTAMPED_ARTIFACT=\"artifacts/20251005-153723-iris\"\n",
    "\n",
    "# Replace <timestamped-folder> with the folder returned by train_data()\n",
    "!dvc add {TIMESTAMPED_ARTIFACT}\n",
    "\n",
    "# Track DVC metadata in Git\n",
    "!git add .\n",
    "!git commit -m \"Add model trained on v2 dataset with metrics\"\n",
    "!git tag -a \"v1.2.2\" -m \"Data version 2 - Artifacts added to DVC\"\n",
    "\n",
    "# Push to DVC remote (GCS)\n",
    "!dvc push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: you are leaving 1 commit behind, not connected to\n",
      "any of your branches:\n",
      "\n",
      "  f03e76e Add model trained on v2 dataset with metrics\n",
      "\n",
      "If you want to keep it by creating a new branch, this may be a good time\n",
      "to do so with:\n",
      "\n",
      " git branch <new-branch-name> f03e76e\n",
      "\n",
      "HEAD is now at 1b8d28b Add model trained on v2 dataset with metrics\n",
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                              |11.0 [00:00,  781entry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.32kentry/s]\n",
      "Applying changes                                      |1.00 [00:00,   166file/s]\n",
      "\u001b[32mA\u001b[0m       data/v1/.ipynb_checkpoints/data.csv\n",
      "1 file added\n",
      "Building workspace index                              |12.0 [00:00, 39.0entry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.03kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout \"v1.2.2\"\n",
    "!dvc pull\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |3.00 [00:00,  132entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                              |5.00 [00:00,  982entry/s]\n",
      "Comparing indexes                                    |5.00 [00:00, 1.18kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "Building workspace index                              |12.0 [00:00, 34.7entry/s]\n",
      "Comparing indexes                                     |12.0 [00:00,  953entry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Pull the versioned model folder from DVC remote\n",
    "!dvc pull artifacts/20251005-153723-iris\n",
    "!dvc checkout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "def get_inference(data_file, model_folder):\n",
    "    # Load evaluation data\n",
    "    eval_df = pd.read_csv(data_file)\n",
    "    X_eval = eval_df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "    \n",
    "    # Load the model from local DVC folder\n",
    "    model_file = os.path.join(model_folder, \"iris_model.joblib\")\n",
    "    model = joblib.load(model_file)\n",
    "    \n",
    "    preds = model.predict(X_eval)\n",
    "    eval_df['predictions'] = preds\n",
    "    print(eval_df.head())\n",
    "    \n",
    "    acc = metrics.accuracy_score(eval_df['predictions'], eval_df['species'])\n",
    "    print(f\"\\nAccuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width species predictions\n",
      "0           5.8          4.0           1.2          0.2  setosa      setosa\n",
      "1           5.7          4.4           1.5          0.4  setosa      setosa\n",
      "2           5.4          3.9           1.3          0.4  setosa      setosa\n",
      "3           5.1          3.5           1.4          0.3  setosa      setosa\n",
      "4           5.7          3.8           1.7          0.3  setosa      setosa\n",
      "\n",
      "Accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "get_inference(\"data/v2/data_augmented.csv\", TIMESTAMPED_ARTIFACT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "#### Demonstrate the ability to traverse through data versions effortlessly using dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Your local changes to the following files would be overwritten by checkout:\n",
      "\t21F1001937_SEPT_2025_MLOps.ipynb\n",
      "Please commit your changes or stash them before you switch branches.\n",
      "Aborting\n",
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                             |12.0 [00:00, 1.23kentry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.34kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "Building workspace index                              |12.0 [00:00, 32.4entry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.01kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout \"v1.1.0\"\n",
    "!dvc pull\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHEAD detached at \u001b[mv1.2.2\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31martifacts/20251005-153723-iris/\u001b[m\n",
      "\t\u001b[31mdata/v1/.ipynb_checkpoints/data.csv\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detached HEAD 86690b0] add part to traverse through data versions\n",
      " 3 files changed, 819 insertions(+), 29 deletions(-)\n",
      " create mode 100644 artifacts/20251005-153723-iris/metrics.txt\n",
      " create mode 100644 data/v1/.ipynb_checkpoints/data.csv\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"add part to traverse through data versions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00, 71.8entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                              |3.00 [00:00,  740entry/s]\n",
      "Comparing indexes                                    |4.00 [00:00, 1.03kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "Building workspace index                              |12.0 [00:00, 42.9entry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.03kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc pull data/v1/data.csv\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m86690b0\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m add part to traverse through data versions\n",
      "\u001b[33m1b8d28b\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.2\u001b[m\u001b[33m)\u001b[m Add model trained on v2 dataset with metrics\n",
      "\u001b[33m4816e0d\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.1\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmaster\u001b[m\u001b[33m)\u001b[m Add augmented Iris dataset v2\n",
      "\u001b[33mc3be2db\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.0\u001b[m\u001b[33m, \u001b[m\u001b[1;33mtag: v1.1.0\u001b[m\u001b[33m)\u001b[m Track Iris v1 dataset with DVC\n",
      "\u001b[33m4b4b681\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.0.0\u001b[m\u001b[33m)\u001b[m Add augmented Iris dataset v2\n",
      "\u001b[33m9195d98\u001b[m Track Iris v1 dataset with DVC\n",
      "\u001b[33md69a849\u001b[m Track data/v1/data.csv with DVC\n",
      "\u001b[33maa36b67\u001b[m stop tracking data/v1/data.csv\n",
      "\u001b[33m57eb339\u001b[m Initialize DVC\n",
      "\u001b[33m05913fd\u001b[m Initial commit of IRIS ML pipeline\n",
      "\u001b[33m3cc7d90\u001b[m Initial commit of IRIS ML pipeline\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3849066a33bd",
    "tags": []
   },
   "source": [
    "## Week 4\n",
    "\n",
    "1. Setup IRIS homework pipeline into a GitHub repository with two branches dev and main\n",
    "2. create evaluation and data validation unit tests using pytest or unittest\n",
    "3. for evaluation and testing, configure the Continuous Integration (CI) with GitHub Actions to fetch the model and data needed for evaluation from DVC configured in Week-3\n",
    "4. push inclusion of pytest code changes to dev branch and raise Pull Request to main branch\n",
    "5. Every branch should have its own CI on push or PR merge\n",
    "6. Run a sanity test using GitHub actions printing a report as a comment using cml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHEAD detached from \u001b[mv1.2.2\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mtrain.py\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m86690b0\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m)\u001b[m add part to traverse through data versions\n",
      "\u001b[33m1b8d28b\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.2\u001b[m\u001b[33m)\u001b[m Add model trained on v2 dataset with metrics\n",
      "\u001b[33m4816e0d\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.1\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmaster\u001b[m\u001b[33m)\u001b[m Add augmented Iris dataset v2\n",
      "\u001b[33mc3be2db\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.2.0\u001b[m\u001b[33m, \u001b[m\u001b[1;33mtag: v1.1.0\u001b[m\u001b[33m)\u001b[m Track Iris v1 dataset with DVC\n",
      "\u001b[33m4b4b681\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1.0.0\u001b[m\u001b[33m)\u001b[m Add augmented Iris dataset v2\n",
      "\u001b[33m9195d98\u001b[m Track Iris v1 dataset with DVC\n",
      "\u001b[33md69a849\u001b[m Track data/v1/data.csv with DVC\n",
      "\u001b[33maa36b67\u001b[m stop tracking data/v1/data.csv\n",
      "\u001b[33m57eb339\u001b[m Initialize DVC\n",
      "\u001b[33m05913fd\u001b[m Initial commit of IRIS ML pipeline\n",
      "\u001b[33m3cc7d90\u001b[m Initial commit of IRIS ML pipeline\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Your local changes to the following files would be overwritten by checkout:\n",
      "\t21F1001937_SEPT_2025_MLOps.ipynb\n",
      "Please commit your changes or stash them before you switch branches.\n",
      "Aborting\n",
      "Collecting                                            |0.00 [00:00,    ?entry/s]\n",
      "Fetching\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/jupyter/.dvc/cache/files/md5'| |0/? [00:00<?,    ?\u001b[A\n",
      "Fetching                                                                        \u001b[A\n",
      "Building workspace index                             |12.0 [00:00, 1.73kentry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 1.04kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "Everything is up to date.\n",
      "Building workspace index                              |12.0 [00:00, 69.8entry/s]\n",
      "Comparing indexes                                    |12.0 [00:00, 2.24kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout \"v1.2.2\"\n",
    "!dvc pull\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git remote -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mHEAD detached from \u001b[mv1.2.2\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   21F1001937_SEPT_2025_MLOps.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mtrain.py\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git config --global user.name \"jemma-mg\"\n",
    "# !git config --global user.email \"jemmamariyageorge@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: No such remote: 'origin'\n"
     ]
    }
   ],
   "source": [
    "!git remote remove origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/jemma-mg/mlops-learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/jemma-mg/mlops-learning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\thttps://github.com/jemma-mg/mlops-learning.git (fetch)\n",
      "origin\thttps://github.com/jemma-mg/mlops-learning.git (push)\n"
     ]
    }
   ],
   "source": [
    "!git remote -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Invalid branch name: 'HEAD'\n"
     ]
    }
   ],
   "source": [
    "!git branch -M main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: src refspec main does not match any\n",
      "\u001b[31merror: failed to push some refs to 'https://github.com/jemma-mg/mlops-learning.git'\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
